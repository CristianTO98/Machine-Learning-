{"metadata": {"language_info": {"name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "file_extension": ".py", "version": "3.5.1", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "cells": [{"metadata": {}, "source": ["# Lab assignment: SVMs in scikit-learn"], "cell_type": "markdown"}, {"metadata": {}, "source": ["In this assignment we will learn how to work with SVMs using the scikit-learn library. We will study in detail their cross-validation, pipelining, training times and kernel functions."], "cell_type": "markdown"}, {"metadata": {}, "source": ["## Guidelines"], "cell_type": "markdown"}, {"metadata": {}, "source": ["Throughout this notebook you will find empty cells that you will need to fill with your own code. Follow the instructions in the notebook and pay special attention to the following symbols.\n", "\n", "<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>You will need to solve a question by writing your own code or answer in the cell immediately below or in a different file, as instructed.</td></tr>\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>This is a hint or useful observation that can help you solve this assignment. You should pay attention to these hints to better understand the assignment.</td></tr>\n", " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td>This is an advanced and voluntary exercise that can help you gain a deeper knowledge into the topic. Good luck!</td></tr>\n", "</table>\n", "\n", "\n", "During the assignment you will make use of several Python packages that might not be installed in your machine. If that is the case, you can install new Python packages with\n", "\n", "    conda install PACKAGENAME\n", "    \n", "if you are using Python Anaconda. Else you should use\n", "\n", "    pip install PACKAGENAME\n", "\n", "You will need the following packages for this particular assignment. Make sure they are available before proceeding:\n", "\n", "* **numpy**\n", "* **matplotlib**\n", "* **scikit-learn**\n", "\n", "The following code will embed any plots into the notebook instead of generating a new window:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["import matplotlib.pyplot as plt\n", "%matplotlib inline"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Lastly, if you need any help on the usage of a Python function you can place the writing cursor over its name and press Caps+Shift to produce a pop-out with related documentation. This will only work inside code cells.\n", "\n", "Let's go!"], "cell_type": "markdown"}, {"metadata": {}, "source": ["## Synthetic dataset"], "cell_type": "markdown"}, {"metadata": {}, "source": ["For the first exercises of this assignment we will use the synthetic dataset generated by the following code:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["import numpy as np\n", "from sklearn.datasets import make_gaussian_quantiles\n", "RND_STATE=np.random.RandomState(42)\n", "# Build first cluster\n", "X1, y1 = make_gaussian_quantiles(cov=2., n_samples=200, n_features=2, n_classes=2, random_state=RND_STATE)\n", "# Build second cluster\n", "X2, y2 = make_gaussian_quantiles(mean=(3, 3), cov=1.5, n_samples=300, n_features=2, n_classes=2, random_state=RND_STATE)\n", "# Fuse them, scaling features differently and switching labels of y2\n", "X = np.concatenate((X1, X2))\n", "X[:, 0] *= 10\n", "X[:, 1] /= 10\n", "y = np.concatenate((y1, -y2+1))"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["The dataset consists of 500 points and consists of two Gaussian clusters. In each cluster points in its inner circle belong to one class, and those in the outer circle belong to the other class. Classes are switched in the second cluster so that it is more challenging to discriminate between both classes.\n", "\n", "If we plot these data we obtain the following:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["from matplotlib.colors import ListedColormap\n", "cm = ListedColormap(['#0000FF', '#FF0000'])    # blue, red\n", "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cm)     \n", "plt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Once we have generated the data *(X, y)*, let us split them into a **training set** and a **test set**. There is a utility function in scikit-learn that does exactly this:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["from sklearn.cross_validation import train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=RND_STATE)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Since *test_size=0.5*, both the training set and the test set will have 250 points each. The number of features is 2, as specified when invoking *make_gaussian_quantiles*:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["print(X_train.shape)\n", "print(X_test.shape)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["## Scikit-learn basics"], "cell_type": "markdown"}, {"metadata": {}, "source": ["Scikit-learn's models for **supervised learning** (SVMs are just one kind of such models) implement a common interface. The most important functions of this interface are the following:\n", "\n", "* **fit(X, y)**: trains the model, fitting it for input patterns *X* and outputs *y*.\n", "* **score(X, y)**: tests an already fitted model with additional data, returning the accuracy obtained (i.e., how similar the outputs given by the model are, compared to the true outputs *y*).\n", "\n", "Thus, all classifiers and regressors in scikit-learn have specific implementations for the above functions. The differences among models (e.g., the different parameters they use) are treated either during construction or internally within these functions.\n", "\n", "For the particular case of SVMs for classification, the implementing class is <a href=http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html>SVC</a>:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["from sklearn.svm import SVC\n", "SVC()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["As you can see, by default scikit-learn builds an SVM with the **RBF kernel**. We know that such an SVM needs 2 parameters: **C** (regularizer between model complexity and classification errors) and **gamma** (kernel width). These are set to 1 and to 'auto' respectively, where 'auto' stands for 1/d (that is, 1 divided by the number of features).\n", "\n", "If you want to create an instance of an SVM with other values for these parameters, you just specify them (the rest of options for the constructor can be safely ignored for now):"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["SVC(C=5, gamma=0.01)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["In practice it is difficult to know which values for *C* and *gamma* work best for a particular dataset. This is why it is common to try with a **grid** of values for both parameters, selecting the pair of values that result in the highest accuracy.\n", "\n", "The first step is selecting the parameter **ranges**. For this exercise, let us use these:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["Cs = np.logspace(-2, 4, 7)\n", "gammas = np.logspace(-4, 4, 9)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["That is, *C* ranges from 0.01 to 10000, whereas *gamma* goes from 0.0001 to 10000, using powers of 10 as intermediate values.\n", "\n", "Recall that in order to avoid **overfitting**, we cannot use the test set for **tuning** these parameters. The following code keeps track of the accuracies obtained for the training set, selecting the best *C* and *gamma*:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["# Accuracies\n", "accs = np.zeros((len(Cs), len(gammas)))   # all accuracies (in matrix form)\n", "best_acc = 0.0   # best accuracy\n", "# For each C\n", "for i, C in enumerate(Cs):\n", "    # For each sigma\n", "    for j, gamma in enumerate(gammas):\n", "        # Create and train SVM\n", "        svm = SVC(C=C, gamma=gamma).fit(X_train, y_train)\n", "        # Keep track of accuracies and best params\n", "        acc = svm.score(X_train, y_train)\n", "        accs[i, j] = acc\n", "        if acc > best_acc:\n", "            best_C = C\n", "            best_gamma = gamma\n", "            best_acc = acc"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["It is illustrative to plot these accuracies in matrix form:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["plt.imshow(accs, interpolation='nearest', cmap=plt.cm.hot)\n", "plt.xlabel('gamma')\n", "plt.ylabel('C')\n", "plt.colorbar()\n", "plt.xticks(np.arange(len(gammas)), gammas, rotation=45)\n", "plt.yticks(np.arange(len(Cs)), Cs)\n", "plt.title('Accuracies obtained')\n", "plt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["The best parameters turn out to be:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["print(\"Best C = \" + str(best_C))\n", "print(\"Best gamma = \" + str(best_gamma))"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Which give a perfect accuracy on the training set:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["print(\"Best accuracy on train = \" + str(best_acc))"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["## Cross-validation"], "cell_type": "markdown"}, {"metadata": {}, "source": ["Perfect accuracy may seem like great news. However, the performance on the test set is not so good:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["best_model = SVC(C=best_C, gamma=best_gamma).fit(X_train, y_train)\n", "best_model.score(X_test, y_test)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["This is a clear sign of overfitting on the training set. If you remember from the theory, ideally we should tune our model fitting it with the training set, but assessing performance on a separate set called **validation set**.\n", "\n", "However, usually there are not enough data to split them into separate training, validation and test sets. If that is the case, we can resort to **cross-validation**, which proceeds as follows:\n", "* The training set is partitioned into *k* subsets (called **folds**).\n", "* *k* different models are trained, using each of the *k* folds to assess performance and the remaining *k-1* folds to fit each model.\n", "* The best model is that whose average performance on the *k* folds is best.\n", "\n", "Programming all this is laborious. Fortunately, the team behind scikit-learn have a whole <a href=http://scikit-learn.org/stable/modules/cross_validation.html>cross-validation module</a>. In addition, the library also has a class specifically designed to perform grid search on the parameters you specify, which is called <a href=http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html>GridSearchCV</a>:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["from sklearn.grid_search import GridSearchCV"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["As the documentation states, in order to build an instance of *GridSearchCV*, you will need to specify two objects:\n", "* An **estimator**, that is, the internal model that is optimized (in this case an *SVC* instance).\n", "* A **parameter grid**, a dictionary where you specify the parameter names and the ranges to perform the search on (these ranges were defined above)."], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Use the code cell below to create a *GridSearchCV* object called *gs* with the SVM as estimator and the range for *C* and *gamma* we defined above.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["GridSearchCV is implemented as well as a model, so its fit(X, y) method is the one that performs the grid search, doing cross-validation under the hood."], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Call the fit method on your *gs* object to perform the grid search on the training set. Do not worry if it takes some time to complete. \n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>\n", "If you build your *GridSearchCV* object above with *verbose=1* you will see a trace of how the cross-validation process is going. For more details, set *verbose=2*. If your PC has several processors you can speed up the whole process by setting *n_jobs* accordingly.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Now that the grid search is complete, let us recover the results obtained. To keep things as before, we would like to overwrite the following variables:\n", "* *accs*: accurary matrix for the different (*C*, *gamma*) pairs.\n", "* *best_acc*: best accuracy.\n", "* *best_C*: best value for *C*.\n", "* *best_gamma*: best value for *gamma*.\n", "* *best_model*: fitted model with the best *C* and the best *gamma*."], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Recover these variables from the fitted *gs* object. Check the *attributes* section in the <a href=http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html>documentation</a>.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>\n", "You do not need to retrain *best_model* from *best_C* and *best_gamma*, it is available directly in the *best\\_estimator\\_* attribute (notice the final underscore). Think also about how to get the accuracies in matrix form from *grid\\_scores\\_*. Numpy's *reshape* function may come in handy.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Replot the accuracies just retrieved. In what way is the resulting figure different from the previous one?\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Reprint the best parameters and their accuracy on training. Explain the changes you observe.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Recalculate the accuracy on test. Dit it improve?\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["## Pipelining"], "cell_type": "markdown"}, {"metadata": {}, "source": ["So far we have assumed that, once the data are loaded, they are ready to be fed to our model without any changes. If you inspect the code above, there is no change in the dataset since creation till it is fed to the *fit(X, y)* method (note that splitting the patterns in validation folds does not change the patterns themselves).\n", "\n", "In practice this will rarely be the case. The data usually need some kind of previous transformations, such as making them all be uniform. This is what is known as **preprocessing**. Combining these transformations with other processes like cross-validation is tricky, as one must make sure that the transformations take place in each of the validation folds, so that the models are only fitted with properly transformed data.\n", "\n", "Once more, we are lucky that scikit-learn makes this task very easy. The class that encapsulates all this is called <a href=http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html>Pipeline</a>:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["from sklearn.pipeline import Pipeline"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Conceptually, a pipeline is defined as a series of **transformers**, followed by one final step which must be an estimator. In the scikit-learn's jargon, this means that the class that takes the last step must implement the method *fit(X, y)*, whereas all the previous classes must implement a new method called *transform(X)* that makes some modification on the input data *X*. If those transformations are data-dependent and have to be learnt, they must also implement another method called *fit_transform(X, y)*.\n", "\n", "Scikit-learn hides this complexity by implementing Pipeline itself as a model as well. Thus, this class complies with the interface we saw in the previous section: \n", "* **fit(X, y)**: calls *fit_transform(X, y)* for all transformers, then calls *fit(X, y)* for the final estimator. This means that all transformations are successively learnt and applied before fitting the model with the properly transformed data.\n", "* **score(X, y)**: calls *transform(X)* for all transformers, then calls *score(X, y)* for the final estimator. The final model requires transformed data, and all the transformations have been learnt by *fit(X, y)*, so they can be now applied directly.\n", "\n", "As the <a href=http://scikit-learn.org/stable/modules/pipeline.html>usage guide</a> describes, in order to build an instance of <a href=http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html>Pipeline</a> you will need to specify a list of **steps**, that is, the transformers and the final estimator you wish to chain. For internal reference, each of these steps must be identified by a name as well as by its class, so the steps are passed as a list of (name, class) pairs. Consider the following example:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["Pipeline([('svm', SVC())])"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Which builds a pipeline with just one estimator (the default SVM), named 'svm'. \n", "\n", "Obviously, a pipeline makes sense only when there is more than a single step. To keep things simple, here we will add just one previous step before the SVM, which performs **normalization to zero mean and unit variance**. This is carried out by the class <a href=http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html>StandardScaler</a>:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["from sklearn.preprocessing import StandardScaler"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["This normalization makes all features be in the same scale, preventing that some feature may have a bigger influence than others just because of the different original scales. If you go back to the dataset's plot, you can see that the scale of the first coordinate is much larger than the second one ([-40, +60] range compared to [-0.3, +0.6]). If we applied an RBF SVM to the data as they are, when computing the kernel function the second coordinate would be negligible compared to the first one. \n", "\n", "However, the figure makes clear that both features are equally important for correct classification, so normalization should improve accuracies considerably. Let us see if this is indeed the case."], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Build a pipeline called *pl* with a *StandardScaler* followed by an SVM. Name both steps as you please.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Performing grid search is trivial now, since *pl* is a valid estimator for the *GridSearchCV* object."], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Rewrite the grid search for the pipeline. This should overwrite again the variables *accs*, *best_acc*, *best_C*, *best_gamma* and *best_model*.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>\n", "Since the pipeline steps are named, the way to access parameters now is 'step\\_\\_parameter' (notice the double underscore). For example, in the pipeline above, we would access the *C* parameter with 'svm\\_\\_C'.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Replot the new accuracies. Are they different from the ones without the scaler?\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Reprint the best parameters and their accuracy both on training and test. How did they change? Are they better now?\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td>\n", "Accuracies do not tell you what the SVM is actually doing internally. Since the data are bidimensional, in this case we can plot what is going on. Write some code that calculates the SVM output (i.e., the distance to the hyperplane) for a mesh of points in the range of the inputs *X*. Your code should plot these distances, as well as the points *(X,y)* passed, using the color convention for the dataset: red for one class and blue for the other one. Explain with your own words the figure you obtain.\n", "</td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>\n", "The distance to the hyperplane is computed by the SVC method **decision\\_function(X)**, which is also part of the interface of scikit-learn's models. Your plot should look similar to the ones that appear in <a href=http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html>this example</a>. Feel free to base your code on the one appearing in the example.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["## Training times"], "cell_type": "markdown"}, {"metadata": {}, "source": ["All the classes that scikit-learn provides for **non-linear SVMs** make use of **LIBSVM** internally. LIBSVM is regarded as the state-of-the-art piece of software for non-linear SVM training. It is based on the classical **SMO** algorithm.\n", "\n", "SVMs are robust and have a very sound mathematical foundation. However, their main drawback in practical use is that, even if we use well-devised software to train them, the complexity is at least quadratic in the number of samples *n*. In big O notation, this is stated as **0(n<sup>2</sup>)**. This precludes the use of non-linear SVMs for very large datasets.\n", "\n", "To illustrate this time growth, we will work with the *adult* dataset, available at the <a href=https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/>LIBSVM website</a>. There are 9 versions of this dataset with increasing training test sizes, ranging from roughly 1600 in the first one to more than 32000 in the last one. They have been downloaded for you in the *data* folder, under the names *adultX.svm*, where X ranges from 1 to 9.\n", "\n", "Let us load for now the smallest version (*adult1.svm*). These .svm files have a special format to save space in disk. Fortunately, scikit-learn has some special functions to load this kind of files:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["from sklearn.datasets import load_svmlight_file, load_svmlight_files"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["As their name makes clear, the first function loads a single file, whereas the second one can load several ones. In the particular case of *adult1.svm*, we want to load also the test set *adult1_test.svm* for parameter tuning, so we can write:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["X_train, y_train, X_test, y_test = load_svmlight_files((\"./data/adult1.svm\", \"./data/adult1_test.svm\"))\n", "print(X_train.shape)\n", "print(X_test.shape)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["As you can see, this dataset has 123 features. Grid search could take long, so here we will use **linear SVMs**. Recall that the default kernel function is RBF, so this has to be specified during construction of the SVC class:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["SVC(kernel='linear')"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Thus, the *gamma* parameter will no longer be applicable, and the only parameter to tune is *C*. Let us use a narrower range now, as training tends to take a long time for large *C*: "], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["Cs = np.logspace(-3, 2, 6)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Use the code of the previous section to tune a linear SVM on the *adult1* dataset.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>\n", "A pipeline with normalization is not necessary in this case, since all features of the dataset turn out to be binary and scales are not an issue. Thus, the estimator inside *GridSearchCV* should be just a linear SVM. \n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>\n", "Since there is a single parameter *C* to optimize, *accs* should become now a vector instead of a matrix.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Print the best *C* and its accuracy both on training and test. Verify that overfitting is not happening.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["We will use this value of *C* for all versions of the *adult* dataset. In order to measure execution times, Python has the native function *time*:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["from time import time"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["To measure how many seconds it takes to execute some code, place that code between two calls to *time* and measure the difference:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["t_start = time()\n", "for i in range(1000000):\n", "    pass    # do nothing\n", "t_end = time()\n", "t_end - t_start"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["One of the improvements of LIBSVM with respect to SMO is its **caching** strategy. For most real-life datasets, there are patterns that are ignored by LIBSVM since they do not influence the solution, whereas there are other patterns that are repeatedly optimized upon in several iterations. If we store in a cache the rows of the kernel matrix corresponding to these repeated patterns, we can save the time needed to recalculate them from scratch.\n", "\n", "Obviously, the larger the cache is, the more rows it is able to store and the bigger its time-saving potential is. This size is controlled by the *cache_size* parameter of *SVC*, which defaults to 200 MB unless specified otherwise on construction:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["best_model"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Let us try with these sizes:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["caches = [100, 200, 500]"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Our goal is to plot training time versus number of patterns, repeating the process for these 3 cache sizes and the increasingly large *adult* versions. There are 9 of these, but we will work with just the first 6:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["num_adults = 6"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["For example, for the default cache of 200 MB, the training time of the smallest *adult* version (the one currently loaded) is:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["t_start = time()\n", "best_model.fit(X_train, y_train)\n", "t_end = time()\n", "t = t_end - t_start\n", "print((len(y_train), t))"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["But this is is just a single point of the plot we want. Your task is to compute the training times for all combinations of cache sizes and *adult* versions, storing them in the following matrix:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["times = np.zeros((num_adults, len(caches)))"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Whereas the dataset sizes will be stored in the following vector:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["sizes = np.zeros((num_adults, 1))"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Write the code that fills *times* and *sizes*.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>\n", "In order to minimize disk accesses, load each version of the *adult* dataset in an outer loop, and do the training for the different cache sizes in an inner loop.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>\n", "Test sets are not needed, so it is enough to use *load_svmlight_file* to load the training sets.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["At this point we have all the necessary information for plotting."], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Use the code below to plots *times* versus *sizes*. What trend do you observe in the figure? Does this comply with the theoretical complexity? From what point does cache size begin to be relevant?\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>\n", "LIBSVM's complexity ranges from O(n<sup>2</sup>) to O(n<sup>3</sup>), depending on factors such as cache efficiency and the dataset itself. For example, the more features the dataset has, the longer training takes, since the complexity of computing the kernel function scales linearly with the number of features.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["for i, c in enumerate(caches):\n", "    plt.plot(sizes, times[:, i], label='Cache ' + str(c) + ' MB')\n", "plt.xlabel('Number of patterns')\n", "plt.ylabel('Training time (seconds)')\n", "plt.legend(loc='best')\n", "plt.title('Training times')\n", "plt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td>\n", "Complete your study with the largest versions (*adult7*, *adult8* and *adult9*) and an additional cache size of 1000 MB. Replot the results. Is the previous trend confirmed?\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>\n", "Because of time complexity, it may well be the case that these large datasets take a long time to train (minutes or even hours, depending on your computer). Use traces in your code to make sure everything is going fine.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["This time growth always happens with non-linear SVMs, even if we use the best algorithms available. Note however that we have been experimenting with a linear SVM. For linear SVMs there are more efficient solvers for large datasets, based on techniques like coordinate gradient descent (LIBLINEAR) or stochastic gradient descent (Pegasos). Scikit-learn knows about this, and provides a specific implementation for a linear SVM that invokes LIBLINEAR called <a href=http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html>LinearSVC</a>:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["from sklearn.svm import LinearSVC\n", "LinearSVC()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Note that there is no cache parameter now, since LIBLINEAR does not make use of a cache. On the other hand, LIBLINEAR is a flexible algorithm that can be used to train other models different than SVMs. To make it train an actual SVM, it must be constructed with *loss='hinge'*. Besides, since it has a random component, we will make use of *RND_STATE*. The rest of parameters are fine with their defaults:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["LinearSVC(loss='hinge', random_state=RND_STATE)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Since this class takes a lot less time to train, we can now use all 9 versions of the *adult* dataset. As there is no cache now, we should reshape *times* to vector form:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["num_adults = 9\n", "times = np.zeros((num_adults, 1))\n", "sizes = np.zeros((num_adults, 1))"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Rewrite the code that fills *times* and *sizes*, using now a *LinearSVC* instance instead of an *SVC* one.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Plot the times obtained versus the training set sizes. Compare this figure with the one you got for the *SVC* class. What is the time complexity for *LinearSVC*?\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["## Custom kernels"], "cell_type": "markdown"}, {"metadata": {}, "source": ["To conclude this assignment, we will deal with custom kernels for non-numerical data. \n", "\n", "As we saw in the pipelining section, scikit-learn implements several transformers that help in adapting data to the specific needs of the different estimators. However, these are usually numerical transformations. What if the data we want to work with are non-numerical, such as images or texts? Good news: scikit-learn also provides transformer classes for these kinds of data. \n", "\n", "In this exercise, we will concentrate on texts. Texts are problematic not only because they are non-numeric, but also because they typically have different lengths, punctuation marks, uppercase and lowercase letters, etcetera. The most common strategy in <a href=http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction>text preprocessing</a> is to transform a series of texts (**corpus**) into a **bag-of-words** representation. In plain language, this means:\n", "\n", "* Standardizing all texts in the corpus into a common form (e.g., lowercase with punctuation removed).\n", "* Splitting them in different units called **tokens** (e.g., words).\n", "* Counting how many times each token appears.\n", "\n", "Thus, each text will be transformed into a vector of length *d*, where *d* is the number of different tokens in the corpus. Its i-th element will be the number of times the i-th token appears in the text. This transformation is carried out by the <a href=http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html>CountVectorizer</a> class:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["from sklearn.feature_extraction.text import CountVectorizer\n", "CountVectorizer()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["By default we can see that it tokenizes texts into lowercase words. Let us illustrate how it works with a simple corpus with 3 short texts:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["corpus = ['This is the first text.', 'This is the second text.', 'And yet another text: the third text.']"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Fitting this corpus splits the different words, which are available in the *vocabulary\\_* attribute:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["cvec = CountVectorizer().fit(corpus)\n", "cvec.vocabulary_"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["We can see that the i-th position of each word is determined by alphabetical order and that punctuation has been removed. The transformed texts will thus be:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["X = cvec.transform(corpus)\n", "X"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["They are stored in a **sparse** matrix X, which only stores the words present. For example, the third text (that with index 2) is:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["print(X[2,:])"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["That is, it has 2 occurrences of the 5-th word in the vocabulary ('text'), and 1 ocurrence of the 0-th, 1-st, 6-th, 7-th and 9-th words ('and', 'another', 'the', 'third' and 'yet'). Words not occurring have a count of 0 and they are not stored in *X* to save space. This sparse format may seem cumbersome for this little example, but it is very compact for extensive corpuses that yield large vocabularies. Usually each text (usually called **document**) will have only a few words from the whole vocabulary, so most of its features will be 0 and there is no need to store that. \n", "\n", "For example, the *20 newsgroups* dataset available in scikit-learn has 18000 documents. It can be loaded with the following utility function:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["from sklearn.datasets import fetch_20newsgroups"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["The documents are pieces of news belonging to 20 categories. Here we will only use 2 of them (atheism and religion) in order to cast a binary classification problem. The source file is available in the *data* folder. Let us load the training data, which has 857 documents (480 talking about atheism, 377 about religion):"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["categories=['alt.atheism', 'talk.religion.misc']\n", "data = fetch_20newsgroups(subset='train', categories=categories, data_home=\"./data\", \n", "                          download_if_missing=False, random_state=RND_STATE)\n", "X_train, y_train = data.data, data.target\n", "print(data.target_names)\n", "print(len(X_train))\n", "print(sum(y_train == 0))\n", "print(sum(y_train == 1))"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["A document looks like this:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["X_train[0]"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Note all the punctuation marks, whitespaces, linebreaks... Fortunately, *CountVectorizer* will take care of all that internally and will transform *X_train* into a numerical matrix suitable for an SVM. There are 3 possibilities for this SVM:\n", "* A linear SVM.\n", "* A non-linear SVM with some existing kernel (e.g., RBF).\n", "* A non-linear SVM with a custom kernel for this task.\n", "\n", "We covered the first 2 kinds of SVMs in the previous sections, so let us consider the third one. The class *SVC* allows to specify a user-defined function for the *kernel* attribute. The <a href=http://scikit-learn.org/stable/modules/svm.html#svm-kernels>documentation</a> specifies that your custom kernel must take as arguments 2 matrices of shape (n1, d), (n2, d) and return a kernel matrix of shape (n1, n2).\n", "\n", "Recall that a kernel measures similarity between patterns. Since our patterns will be word counts, we should do some operation that measures how similar two documents are, using their word-count vectors. A possibility that comes to mind is to count **how many words appear in both documents**. The following function calculates this:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["def words_in_common(X1, X2):\n", "    X1_bin = (X1 > 0).astype(np.int)     # binarize word counts in corpus X1: 1 = word appears, 0 = word does not appear\n", "    X2_bin = (X2 > 0).astype(np.int)     # same for second corpus X2\n", "    # Now, for two documents in binary vector form, the number of matching words is the sum of 1s in the same positions.\n", "    # For example, [0, 1, 1, 0] and [1, 1, 1, 0] have two 1s in the same position (2nd and 3rd), so they have 2 words in common.\n", "    # Observation: this is the same as the sum of the dot product of both vectors.\n", "    # Thus, in matrix form we just have to transpose the second corpus, and call standard matrix multiplication.\n", "    return X1_bin.dot(X2_bin.T)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Let us verify it works as expected:"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["print(words_in_common(X, X))"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["Obviously, each document has all words in common with itself. The first one has 4 words in common with the second one (they only differ in the words 'first' and 'second'). The remaining cells are also correct, and the resulting matrix is symmetric, as every kernel matrix should be.\n", "\n", "Now we are ready to try a pipeline with a *CountVectorizer* and an SVM with this custom kernel. We will use the same values for *C* than in the previous exercise."], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Build the pipeline and optimize it with grid search, as you did in the previous sections.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td>\n", "Report the value of *C* obtained, as well as the accuracies on training and test. How good are they?\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>\n", "You will need to load the test data. Load them like the training data.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": ["####### INSERT YOUR CODE HERE"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td>\n", "One problem with the kernel *words_in_common* is that the information about how many times each word appears is lost. For example, if a given word W appears in a document D1 twice and in another document D2 just once, both documents are considered to match 100% for W. The same happens if that word appears twice both in D1' and D2'. In terms of similarity, though, it seems natural to consider that D1' and D2' are more similar for W than D1 and D2. A measure that takes this into account is the <a href=https://en.wikipedia.org/wiki/Cosine_similarity>cosine similarity</a>, defined as **u<sup>T</sup>v / (||u||*||v||)**, where **u** and **v** are the word-count vectors for both documents and **||\u00b7||** stands for the L2 norm. Define a function that implements cosine similarity, and tune the resulting pipeline. Can you obtain better results with this kernel?\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>\n", "Recall that ||u|| = sqrt(u<sup>T</sup>u). Thus, you can implement this kernel in terms of numpy's *dot* function. Scikit-learn's function <a href=http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html>normalize</a> can also be helpful.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td>\n", "Compare your results with the ones obtained by a linear SVM. Even if linear SVMs tend to give worse results, they have the advantage of the model's interpretability. Since the weight vector **w** does not depend on an unknown feature map, we can retrieve it after training. Moreover, because the decision function is **w\u00b7x + b** and one class is positive (y = +1) and the other is negative (y = -1), the components of **w** can be interpreted as the importance of the variables **x**: the more positive the i-th component of **w**, the more related is that variable to the positive class. Conversely, the more negative, the more related to the negative class. In this particular case, the features **x** are word counts, so the sign of **w** gives us how much a word indicates atheism (positive class) or religion (negative class). Once you have tuned your linear SVM, find the 10 most indicative words for each class. Do they make sense?\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>\n", "**w** is available in the *coef\\_* attribute of the SVM. Since it is stored as a sparse matrix, you will need to transform it into a dense vector.\n", " </td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<table align=\"left\">\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td>\n", "Once you retrieve **w**, you can find its largest and smallest components with numpy's *argsort* function. Note that the *CountVectorizer*'s *vocabulary_* attribute is in dictionary form, so you cannot find the words from their indices. Use instead the word list returned by the method *get_feature_names* of the *CountVectorizer* class.\n", "</td></tr>\n", "</table>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["<center>\n", "~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.<br>\n", "                          THIS IS THE END OF THE ASSIGNMENT<br>\n", "~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.<br>\n", "</center>"], "cell_type": "markdown"}], "nbformat_minor": 0, "nbformat": 4}